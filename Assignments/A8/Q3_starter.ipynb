{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Breast Cancer LASSO Exploration\n",
    "## Prepare workspace\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "X = loadmat(\"BreastCancer.mat\")['X']\n",
    "y = loadmat(\"BreastCancer.mat\")['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "la_num = 20\n",
    "lam_vals = np.logspace(-6, 2, num=la_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ista_solve_hot( A, d, la_array ):\n",
    "    # ista_solve_hot: Iterative soft-thresholding for multiple values of\n",
    "    # lambda with hot start for each case - the converged value for the previous\n",
    "    # value of lambda is used as an initial condition for the current lambda.\n",
    "    # this function solves the minimization problem\n",
    "    # Minimize |Ax-d|_2^2 + lambda*|x|_1 (Lasso regression)\n",
    "    # using iterative soft-thresholding.\n",
    "    max_iter = 10**4\n",
    "    tol = 10**(-3)\n",
    "    tau = 1/np.linalg.norm(A,2)**2\n",
    "    n = A.shape[1]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    X = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        for j in range(max_iter):\n",
    "            z = w - tau*(A.T@(A@w-d))\n",
    "            w_old = w\n",
    "            w = np.sign(z) * np.clip(np.abs(z)-tau*each_lambda/2, 0, np.inf)\n",
    "            X[:, [i]] = w\n",
    "            if np.linalg.norm(w - w_old) < tol:\n",
    "                break\n",
    "    return X\n",
    "\n",
    "def ridge_many(A,d,la_array):\n",
    "    n = A.shape[1]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    X = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        w = A.T@np.linalg.inv(A@A.T+each_lambda*np.identity(A.shape[0]))@d\n",
    "        X[:, [i]] = w\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_err_rate(X, y, w):\n",
    "    err = 0\n",
    "    y_head = X @ w\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] != np.sign(y_head[i])):\n",
    "            err+=1\n",
    "    err_rate = err / len(y)\n",
    "    return err_rate\n",
    "\n",
    "\n",
    "def findOptLamdaIndx(X, y, W):\n",
    "    err_rates = np.zeros(la_num)\n",
    "    for i in range(la_num):\n",
    "        w = W[:, [i]]\n",
    "        err_rates[i] = find_err_rate(X, y, w);\n",
    "    lamda_opt_indx = np.argsort(err_rates)[0]\n",
    "    return lamda_opt_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  10-fold CV \n",
    "\n",
    "# each row of setindices denotes the starting an ending index for one\n",
    "# partition of the data: 5 sets of 30 samples and 5 sets of 29 samples\n",
    "setindices = [[1,30],[31,60],[61,90],[91,120],[121,150],[151,179],[180,208],[209,237],[238,266],[267,295]]\n",
    "\n",
    "# each row of holdoutindices denotes the partitions that are held out from\n",
    "# the training set\n",
    "holdoutindices = [[1,2],[2,3],[3,4],[4,5],[5,6],[7,8],[9,10],[10,1]]\n",
    "\n",
    "cases = len(holdoutindices)\n",
    "\n",
    "# be sure to initiate the quantities you want to measure before looping\n",
    "# through the various training, validation, and test partitions\n",
    "\n",
    "err_rates_LASSO = np.zeros(cases)\n",
    "sq_error_LASSO = np.zeros(cases)\n",
    "\n",
    "err_rates_RR = np.zeros(cases)\n",
    "sq_error_RR = np.zeros(cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate for LASSO is:  0.3001436781609196\n",
      "Average squred error for LASSO is:  5.129196576172512\n"
     ]
    }
   ],
   "source": [
    "# Loop over various cases\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(295))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = X[v1_ind,:]\n",
    "    bv1 = y[v1_ind]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = X[v2_ind,:]\n",
    "    bv2 = y[v2_ind]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = X[trn_ind,:]\n",
    "    bt = y[trn_ind]\n",
    "    \n",
    "    # print(len(v1_ind), len(v2_ind), len(trn_ind))\n",
    "    # Use training data to learn classifier\n",
    "    W = ista_solve_hot(At,bt,lam_vals) # W across a range of lamdas\n",
    "    \n",
    "    # Find best lambda value using first validation set\n",
    "    lamda_opt_indx = findOptLamdaIndx(Av1, bv1, W)\n",
    "    w_opt = W[:, [lamda_opt_indx]]\n",
    "    \n",
    "    # evaluate performance on second validation set, and accumulate performance metrics\n",
    "    err_rate = find_err_rate(Av2, bv2, w_opt)\n",
    "    err_rates_LASSO[j] = err_rate\n",
    "    sq_error = np.linalg.norm(Av2 @ w_opt - bv2, ord=2)\n",
    "    sq_error_LASSO[j] = sq_error\n",
    "\n",
    "print(\"Average error rate for LASSO is: \", np.average(err_rates_LASSO))\n",
    "print(\"Average squred error for LASSO is: \", np.average(sq_error_LASSO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate for Ridge Regression is:  0.30833333333333335\n",
      "Average squred error for Ridge Regression is:  4.962352789866199\n"
     ]
    }
   ],
   "source": [
    "# Loop over various cases\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(295))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = X[v1_ind,:]\n",
    "    bv1 = y[v1_ind]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = X[v2_ind,:]\n",
    "    bv2 = y[v2_ind]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = X[trn_ind,:]\n",
    "    bt = y[trn_ind]\n",
    "    \n",
    "    # print(len(v1_ind), len(v2_ind), len(trn_ind))\n",
    "    # Use training data to learn classifier\n",
    "    W = ridge_many(At,bt,lam_vals) # W across a range of lamdas\n",
    "    \n",
    "    # Find best lambda value using first validation set\n",
    "    lamda_opt_indx = findOptLamdaIndx(Av1, bv1, W)\n",
    "    w_opt = W[:, [lamda_opt_indx]]\n",
    "    \n",
    "    # evaluate performance on second validation set, and accumulate performance metrics\n",
    "    err_rate = find_err_rate(Av2, bv2, w_opt)\n",
    "    err_rates_RR[j] = err_rate\n",
    "    sq_error = np.linalg.norm(Av2 @ w_opt - bv2, ord=2)\n",
    "    sq_error_RR[j] = sq_error\n",
    "\n",
    "print(\"Average error rate for Ridge Regression is: \", np.average(err_rates_RR))\n",
    "print(\"Average squred error for Ridge Regression is: \", np.average(sq_error_RR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
