{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter\n",
    "from numpy import linalg as LA\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods # \n",
    "def preprocess(filename):\n",
    "    # open file\n",
    "    file = open(filename, \"rb\")\n",
    "    lines = file.read() # convert all to lowercase; type = str\n",
    "    # tokenize\n",
    "    tokens = lines.split()\n",
    "    # pre-processing\n",
    "    ct = Counter()\n",
    "    for token in tokens:\n",
    "        ct[token]+= 1\n",
    "    return ct\n",
    "\n",
    "def get_TFIDF_vector(doc, templ, corp_length, file_count):\n",
    "    max_c = doc.most_common(1)[0][1]\n",
    "    # print(max_c)\n",
    "    v = [0] * corp_length\n",
    "    for w in doc:\n",
    "        c = doc.get(w)\n",
    "        tf_w = c / max_c\n",
    "        idf_w = math.log(file_count / docs_contain_W(w), 10)\n",
    "        v[templ.index(w)] = tf_w * idf_w \n",
    "    return v\n",
    "\n",
    "def docs_contain_W(w):\n",
    "    count = 0\n",
    "    for doc in docs:\n",
    "        if doc.__contains__(w):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def build_corpora(docs):\n",
    "    corp_temp = Counter()\n",
    "    for doc in docs:\n",
    "        corp_temp += doc\n",
    "    occurrance = sum(corp_temp.values())\n",
    "    wordType =  len(corp_temp)\n",
    "    corpora = []\n",
    "    for x, y in list(corp_temp.most_common()):\n",
    "        corpora.append(x)\n",
    "    return corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 Warm up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "doc1 = preprocess('./q1/doc1.txt')\n",
    "doc2 = preprocess('./q1/doc2.txt')\n",
    "doc3 = preprocess('./q1/doc3.txt')\n",
    "file_count = 3\n",
    "docs = [doc1, doc2, doc3]\n",
    "\n",
    "# build corpora\n",
    "corpora = build_corpora(docs)\n",
    "corp_length = len(corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) bulid TF-IDF expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doc1      ', 'doc2      ', 'doc3']\n",
      "[[0.         0.47712125 0.        ]\n",
      " [0.47712125 0.         0.        ]\n",
      " [0.47712125 0.         0.        ]\n",
      " [0.         0.31808084 0.        ]\n",
      " [0.         0.31808084 0.        ]\n",
      " [0.         0.31808084 0.        ]\n",
      " [0.23856063 0.         0.        ]\n",
      " [0.23856063 0.         0.        ]\n",
      " [0.23856063 0.         0.        ]\n",
      " [0.23856063 0.         0.        ]\n",
      " [0.         0.15904042 0.        ]\n",
      " [0.         0.15904042 0.        ]\n",
      " [0.         0.15904042 0.        ]\n",
      " [0.         0.15904042 0.        ]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]\n",
      " [0.         0.         0.47712125]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf = np.zeros((corp_length, file_count))\n",
    "for i in range(file_count):\n",
    "    tf_idf[:, i] = get_TFIDF_vector(docs[i], corpora, corp_length, file_count)\n",
    "    \n",
    "titles = [\"doc1      \", \"doc2      \", \"doc3\"]\n",
    "print(titles)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_doc matrix\n",
      "[[-0.         -0.         -0.79520209]\n",
      " [-1.96722133 -0.         -0.        ]\n",
      " [ 0.          0.82639825  0.        ]]\n",
      "\n",
      "\n",
      "topic_term matrix\n",
      "[[ 0.          0.          0.47712125]\n",
      " [ 0.         -0.47712125  0.        ]\n",
      " [ 0.         -0.47712125 -0.        ]\n",
      " [ 0.          0.          0.31808084]\n",
      " [ 0.          0.          0.31808084]\n",
      " [ 0.          0.          0.31808084]\n",
      " [ 0.         -0.23856063 -0.        ]\n",
      " [ 0.         -0.23856063 -0.        ]\n",
      " [ 0.         -0.23856063 -0.        ]\n",
      " [ 0.         -0.23856063 -0.        ]\n",
      " [ 0.          0.          0.15904042]\n",
      " [ 0.          0.          0.15904042]\n",
      " [ 0.          0.          0.15904042]\n",
      " [ 0.          0.          0.15904042]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]\n",
      " [-0.47712125  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "U,s,VT = np.linalg.svd(tf_idf,full_matrices=False)\n",
    "topic_doc = s * VT\n",
    "topic_term = s * U\n",
    "print(\"topic_doc matrix\")\n",
    "print(topic_doc)\n",
    "print(\"\\n\")\n",
    "print(\"topic_term matrix\")\n",
    "print(topic_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2  Cosine Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) build TF-IDF expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.00745502]\n",
      " [0.         0.         0.00745502]\n",
      " [0.         0.         0.00745502]]\n"
     ]
    }
   ],
   "source": [
    "# read files\n",
    "doc1 = preprocess('./q2/doc1.txt')\n",
    "doc2 = preprocess('./q2/doc2.txt')\n",
    "doc3 = preprocess('./q2/doc3.txt')\n",
    "file_count = 3\n",
    "docs = [doc1, doc2, doc3]\n",
    "\n",
    "# build corpora\n",
    "corpora = build_corpora(docs)\n",
    "corp_length = len(corpora)\n",
    "\n",
    "# build tf-itf expressions\n",
    "tf_idf = np.zeros((corp_length, file_count))\n",
    "for i in range(file_count):\n",
    "    tf_idf[:, i] = get_TFIDF_vector(docs[i], corpora, corp_length, file_count)\n",
    "    \n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    cos_sim = dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cosine similarity between doc 1 and doc 2 files =  0.04619458366523629\n",
      "the cosine similarity between doc 1 and doc 3 files =  0.005158837754693584\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity of 2 related files\n",
    "sim1 = cosine_sim(tf_idf[:, 0], tf_idf[:, 1])\n",
    "print(\"the cosine similarity between doc 1 and doc 2 files = \", sim1)\n",
    "\n",
    "# cosine similarity of 2 unrelated files\n",
    "sim2 = cosine_sim(tf_idf[:, 0], tf_idf[:, 2])\n",
    "print(\"the cosine similarity between doc 1 and doc 3 files = \", sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: SVD in LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) build SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files \n",
    "list_of_names = np.arange(1, 31)\n",
    "group1 = np.arange(0, 20)\n",
    "group2 = np.arange(10, 20)\n",
    "group3 = np.arange(20, 30)\n",
    "file_count = len(list_of_names)\n",
    "docs = []\n",
    "for i in range(file_count):\n",
    "    doc = preprocess(\"./q3/doc\" + str(list_of_names[i]) + \".txt\")\n",
    "    docs.append(doc)\n",
    "\n",
    "# build corpora\n",
    "corpora = build_corpora(docs)\n",
    "corp_length = len(corpora)\n",
    "\n",
    "# build TF-IDF expressions\n",
    "tf_idf = np.zeros((corp_length, file_count))\n",
    "for i in range(file_count):\n",
    "    tf_idf[:, i] = get_TFIDF_vector(docs[i], corpora, corp_length, file_count)\n",
    "\n",
    "# regular SVD\n",
    "U,s,VT = np.linalg.svd(tf_idf,full_matrices=False)\n",
    "topic_doc = s * VT.T\n",
    "topic_term = s * U\n",
    "\n",
    "topic_doc = np.absolute(topic_doc)\n",
    "topic_doc = topic_doc / sum(topic_doc)\n",
    "np.set_printoptions(suppress=True)\n",
    "np.savetxt(\"topic_doc.csv\", topic_doc, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra-group similarities = \n",
      " [1.0000000000000002, 0.46119291712467914, 0.3128200817977986, 0.351194160450727, 0.20652809802211392, 0.5497952825846238, 0.103929701466062, 0.15978044041613068, 0.24160164015197202, 0.12674644914591957, 0.1423517131625161, 0.15977641506823348, 0.22995066374834, 0.16623590913703315, 0.16084885971778035, 0.4101032674780667, 0.15033430454526567, 0.3151120636210163, 0.13278481390004498, 0.1539124493776992]\n",
      "average intra-group similarity =  0.23868417004821174\n",
      "inter-group similarities = \n",
      " [0.11888892678785296, 0.07532405121376341, 0.10620201007276478, 0.2640757139552464, 0.22834167732503063, 0.24132929233602696, 0.1359301239014523, 0.05638144038980467, 0.06530661970879373, 0.04361743876548238]\n",
      "average inter-group similarity =  0.1335397294456218\n"
     ]
    }
   ],
   "source": [
    "# intra-group similarity for a given doc\n",
    "ref_file = topic_doc[:, 0]  # doc1.txt\n",
    "intra_sims = [];\n",
    "for i in group1:\n",
    "    sim = cosine_sim(topic_doc[:,i], ref_file)\n",
    "    intra_sims.append(sim)\n",
    "print(\"intra-group similarities = \\n\", intra_sims)\n",
    "intra_sims = np.delete(intra_sims, [0])\n",
    "avg_intra_sim = np.average(intra_sims)\n",
    "print(\"average intra-group similarity = \", avg_intra_sim)\n",
    "\n",
    "# inter-group similarity for the same doc\n",
    "inter_sims = [];\n",
    "for i in range(file_count):\n",
    "    if i in group1:\n",
    "        continue\n",
    "    sim = cosine_sim(topic_doc[:,i], ref_file)\n",
    "    inter_sims.append(sim)\n",
    "print(\"inter-group similarities = \\n\", inter_sims)\n",
    "avg_inter_sim = np.average(inter_sims)\n",
    "print(\"average inter-group similarity = \", avg_inter_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
